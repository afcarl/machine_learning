{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA CREDIT HOMEWORK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import multivariate_normal\n",
    "import seaborn as sns; sns.set()\n",
    "from demo import fairness_demo\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1  [25 points]\n",
    "Consider the four datasets returned from the function get_dataset($d$) for $d=2,3,4, \\& \\;5$. Here $d$ is the dimensionality of the non-sensitive covariates, which are returned in the matrix $X$, whereas the vectors $y$ and $x_{\\rm{sensitive}}$ store the target labels and sensitive covariate, respectively. (As such the structure of the data is exactly analagous to what we have in the fairness demo notebook from the lecture.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gaussian_data(mean, cov, class_label, n_samples):\n",
    "    nv = multivariate_normal(mean = mean, cov = cov)\n",
    "    X = nv.rvs(n_samples)\n",
    "    y = np.ones(n_samples, dtype=float) * class_label\n",
    "    return X,y\n",
    "\n",
    "### this function returns the dataset\n",
    "### e.g. X, y, x_sensitive = get_dataset(2)\n",
    "\n",
    "def get_dataset(d):\n",
    "    np.random.seed(5)\n",
    "    mu1 = 0.5*np.ones(d)\n",
    "    mu2 = -0.5*np.ones(d)\n",
    "    sigma1 = np.eye(d)\n",
    "    sigma2 = np.eye(d)\n",
    "    X1, y1 = get_gaussian_data(mu1, sigma1, 1, 10000*d) # positive class\n",
    "    X2, y2 = get_gaussian_data(mu2, sigma2, -1, 10000*d) # negative class\n",
    "\n",
    "    X = np.vstack((X1, X2)) # non-sensitive covariates\n",
    "    y = np.hstack((y1, y2)) # class labels\n",
    "    x_sensitive = np.ones(X.shape[0])\n",
    "    x_sensitive[X[:,0]<0.0] = 0 # sensitive covariate; \n",
    "                                # 0 is the protected class, 1 is the non-protected class\n",
    "    return X, y, x_sensitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part a)  [10 points]\n",
    "Using the logistic regression classifier provided by the python class fairness_demo (just like in the lecture notebook) calculate the accuracy and p%-rule ratio for all four datasets using the unconstrained classifier (i.e. no fairness constraints are imposed).\n",
    "\n",
    "# part b) [10 points]\n",
    "Note that for all four datasets the \"four-fifths rule\" is very much not satisfied. For each dataset impose the minimum fairness constraint such that the four-fiths rule is satisfied. What is the loss in accuracy for each dataset as compared to the unconstrained classifier performance?\n",
    "\n",
    "# part c) [5 points]\n",
    "Notice that (as least as far as the four datasets for $d=2,3,4, \\& \\;5$ are concerned) as the dimension $d$ increases  the following things happen:\n",
    "\n",
    "- the accuracy increases\n",
    "- the p%-rule ratio for the unconstrained classifier increases\n",
    "- the accuracy losses as calculated in part b decrease (at least approximately up to fluctuations)\n",
    "\n",
    "Look at the function get_dataset($d$) and consider how the generated dataset changes as a function of $d$. Do you expect the behavior described above to continue for all values of $d>5$? If so, explain why. If not, explain why not.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2  [10 points]\n",
    "\n",
    "Read the following review by Barocas and Selbst (or as much of the review as you find interesting):\n",
    "\n",
    "http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899\n",
    "\n",
    "Answer the following questions on the basis of what you've read.\n",
    "\n",
    "# part a)\n",
    "\n",
    "Consider the logic underlying the \"fairness aware\" classifier we explored in the previous problem. Consider the principle of nondiscrimination versus the principle of antisubordination. Which (if any) of the two principles is more in line with the approach taken by the algorithm? Why?\n",
    "\n",
    "# part b)\n",
    "\n",
    "Consider the \"fairness aware\" classifier we explored in the previous problem. In itself does it offer a solution to the problem of \"masking\" as described in the review?\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3  [5 points]\n",
    "\n",
    "Consider the following illustration of a dataset in which the positive target labels are marked with plus signs, the green points constitute the non-protected class, and the blue points constitute the protected class. The distribution of the non-protected class is illustrated on the left, the distribution of the protected class is illustrated in the middle, and the graphic on the right shows the combined dataset.\n",
    "\n",
    "<img src=\"dataset.png\">\n",
    "\n",
    "Consider applying the \"fairness aware\" classifier in Problem 1 to the combined dataset, imposing fairness constraints such that the four-fifths rule is satisfied. Do you expect the loss of accuracy as you go from the unconstrained to the constrained classifier to be large or small? Why?\n",
    "\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4  [15 points]\n",
    "#### (This is question 2.2 from Dunning's book)\n",
    "\n",
    "In a study of the effect of police presence on the incidence of crime, Di Tella and Schargrodsky (2004) write:\n",
    "\n",
    "“Following a terrorist attack on the main Jewish center in Buenos Aires, Argentina, in July\n",
    "1994, all Jewish institutions received police protection… Because the geographical\n",
    "distribution of these institutions can be presumed to be exogenous in a crime regression, this hideous event constitutes a natural experiment.”\n",
    "\n",
    "The authors find that blocks which were allocated extra police forces due to the presence of a Jewish institution experienced lower motor vehicle theft rates.  The control group consists of blocks in the same neighborhoods that do not have Jewish institutions.\n",
    "\n",
    "Answer the following three questions __in at least 6-10 sentences__.\n",
    "\n",
    "### part a) \n",
    "\n",
    "What do the authors mean by “presumed exogenous in a crime regression” and what is the relationship to as-if random assignment?  \n",
    "### part b) \n",
    "What are some potential threats to as-if random assignment?  [give at least two examples of potential threats]\n",
    "### part c) \n",
    "How might these threats be evaluated empirically?\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "\n",
    "That the geographical distribution of the Jewish instiutions is \"presumed exogenous in a crime regression\" means that they presume the locatons do not have a causal relationship with crime such as motor theft.  Since they presume that there is no causal relationship between the locations and crime, then the groups near a Jewish instituion can be separated from those not near one as a \"random\" treatment and control group with \"as-if random assignment.\"\n",
    "\n",
    "### b)\n",
    "\n",
    "* There may be factors that the authors didn't consider which are not evenly distributed between the two groups.\n",
    "* The treatment and control groups are formed post-hoc and the experiment is formed given that, instead of forming an experiment and then creating a randomized trial.  Because there is an outside force which created these two groups, there could be other external factors affecting the results.  For example, if the above experiment is supposed to test the effect of police force on preventing motor theft, it may be that the communities themselves are just on higher alert due to the terror attack, and not the police force, that is reducing theft\n",
    "\n",
    "### c)\n",
    "\n",
    "* This can be evaluated by increasing the number of features being considering and seeing if there is an unequal distribution between the two groups.\n",
    "* Look for either Jewish areas which didn't recieve an increased police presenence, or places with increased police presence for another reason and see if either see similar impacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5  [45 points]\n",
    "Consider the Titanic dataset below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"https://serv.cusp.nyu.edu/classes/ML_2016_Spring/Bonus/titanic3.csv\").dropna(subset=['age'])\n",
    "\n",
    "target = data['survived']\n",
    "X = data[['age', 'sex', 'pclass', 'sibsp', 'parch']]\n",
    "X = pd.get_dummies(X)\n",
    "X_train, X_test, target_train, target_test = train_test_split(\n",
    "    X, target, test_size=0.25, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(pred, target_test):\n",
    "    print(\"Classification accuracy for test set =\", 1.0*sum(target_test==pred)/len(pred))\n",
    "    \n",
    "    print(\"Precision (Survived):\", precision_score(target_test, pred))\n",
    "    print(\"Precision (Didn't Survive):\", precision_score(target_test, pred, pos_label=0))\n",
    "    \n",
    "    print(\"Recall (Survived):\", recall_score(target_test, pred))\n",
    "    print(\"Recall (Didn't Survive):\", recall_score(target_test, pred, pos_label=0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data dictionary\n",
    "NAME: titanic3<br>\n",
    "SIZE: 1309 Passengers, 14 Variables<br><br>\n",
    "\n",
    "VARIABLE DESCRIPTIONS<br>\n",
    "Pclass: Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd) <br>\n",
    "survival: Survival (0 = No; 1 = Yes)<br>\n",
    "name: Name<br>\n",
    "sex: Sex<br>\n",
    "age: Age<br>\n",
    "sibsp: Number of Siblings/Spouses Aboard<br>\n",
    "parch: Number of Parents/Children Aboard<br>\n",
    "ticket: Ticket Number<br>\n",
    "fare: Passenger Fare (British pound)<br>\n",
    "cabin: Cabin<br>\n",
    "embarked: Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)<br>\n",
    "boat: Lifeboat<br>\n",
    "body: Body Identification Number<br>\n",
    "home.dest: Home/Destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part a) [30 points]\n",
    "\n",
    "Your goal is to train a classifier for the binary attribute “survival\" using age, sex, pclass, sibsp, and parch as features. You will do so using three different machine learning techniques:\n",
    "\n",
    "i) Naive Bayes Classification. [10 points]\n",
    "\n",
    "ii) Support Vector Machine. Try a linear SVM with soft margins as well as kernel SVM with polynomial and Gaussian kernels. Make sure to use a validation set to choose hyperparameters for each model where applicable. [10 points]\n",
    "\n",
    "iii) Random Forest Classification. [10 points]\n",
    "\n",
    "For each of the three models report out-of-sample accuracy--in order to do so, you will of course need to split the dataset into a training dataset and a test dataset.\n",
    "\n",
    "# part b)  [15 points]\n",
    "\n",
    "Repeat the exercise in part a, this time using cross validation. Report the mean accuracy for each model after doing 10 random splits of the data into train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) Naive Bayes Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy for test set = 0.824427480916\n",
      "Precision (Survived): 0.782178217822\n",
      "Precision (Didn't Survive): 0.850931677019\n",
      "Recall (Survived): 0.766990291262\n",
      "Recall (Didn't Survive): 0.861635220126\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, target_train)\n",
    "pred = gnb.predict(X_test)\n",
    "\n",
    "report(pred, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy for test set = 0.812977099237\n",
      "Precision (Survived): 0.759615384615\n",
      "Precision (Didn't Survive): 0.848101265823\n",
      "Recall (Survived): 0.766990291262\n",
      "Recall (Didn't Survive): 0.842767295597\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, target_train)\n",
    "pred = svc.predict(X_test)\n",
    "\n",
    "report(pred, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy for test set = 0.843511450382\n",
      "Precision (Survived): 0.787037037037\n",
      "Precision (Didn't Survive): 0.883116883117\n",
      "Recall (Survived): 0.825242718447\n",
      "Recall (Didn't Survive): 0.85534591195\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='poly', max_iter=-1, tol=.01, degree=2)\n",
    "svc.fit(X_train, target_train)\n",
    "pred = svc.predict(X_test)\n",
    "\n",
    "report(pred, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy for test set = 0.835877862595\n",
      "Precision (Survived): 0.794117647059\n",
      "Precision (Didn't Survive): 0.8625\n",
      "Recall (Survived): 0.78640776699\n",
      "Recall (Didn't Survive): 0.867924528302\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train, target_train)\n",
    "pred = svc.predict(X_test)\n",
    "\n",
    "report(pred, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii) Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy for test set = 0.793893129771\n",
      "Precision (Survived): 0.702479338843\n",
      "Precision (Didn't Survive): 0.872340425532\n",
      "Recall (Survived): 0.825242718447\n",
      "Recall (Didn't Survive): 0.77358490566\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=500)\n",
    "clf = clf.fit(X_train, target_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "report(pred, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Accuracy: 0.78 (+/- 0.15)\n",
      "Linear SVM - Accuracy: 0.78 (+/- 0.14)\n",
      "RBF SVM - Accuracy: 0.78 (+/- 0.17)\n",
      "Poly SVM - Accuracy: 0.80 (+/- 0.15)\n",
      "Random Forest - Accuracy: 0.73 (+/- 0.18)\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "for clf, name in [\n",
    "    (GaussianNB(), 'Naive Bayes'), \n",
    "    (SVC(kernel='linear'), 'Linear SVM'),\n",
    "    (SVC(kernel='rbf'), 'RBF SVM'),\n",
    "    (SVC(kernel='poly', tol=.1, degree=2), 'Poly SVM'),\n",
    "    (RandomForestClassifier(n_jobs=-1, n_estimators=300), 'Random Forest')\n",
    "]:\n",
    "    scores = cross_val_score(clf, X, target, cv=10, scoring='accuracy')\n",
    "    print(name, \"- Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
