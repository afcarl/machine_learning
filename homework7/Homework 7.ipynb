{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Display plots in the notebook\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make plots prettyful\n",
    "pl.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('original_with_duplicates_noid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\docmario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "values = scale(pd.get_dummies(data, columns=['year', 'day', 'month', 'suspect.race', 'suspect.build', 'suspect.sex', 'location.housing']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements via clustering: 997\n"
     ]
    }
   ],
   "source": [
    "db = DBSCAN(min_samples=1, eps=1)\n",
    "labels = db.fit_predict(values)\n",
    "print(\"Number of unique elements via clustering:\", len(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements via row-wise detection: 997\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique elements via row-wise detection:\", len(data[~data.duplicated()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first converted the categorical variables to dummy variablse. I used DBSCAN to cluster the data using all the columns in the dataset.  I used DBSCAN because it does not require the number of clusters to be specified and we know that the duplicate points will be in the same place, so the distance can be set to be small.\n",
    "\n",
    "I used pandas's built in duplicate detection to validate this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\docmario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('original_with_errors_noid.csv')\n",
    "data = pd.get_dummies(data, columns=['year', 'day', 'month', 'suspect.race', 'suspect.build', 'suspect.sex', 'location.housing'])\n",
    "values = scale(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal eps: 1.6\n",
      "Features with errors: {'suspect.weight', 'suspect.age'}\n"
     ]
    }
   ],
   "source": [
    "def getErrorFeatures(labels):\n",
    "    # Figure out which features had errors introduced by diffing the rows in each cluster and picking out the non-zero features\n",
    "    error_columns = set()\n",
    "    for i in np.nonzero(np.bincount(labels) > 1)[0]:\n",
    "        columns = data.columns[np.nonzero(np.diff(values[labels == i], axis=0)[0])]\n",
    "        for c in columns:\n",
    "            error_columns.add(c)\n",
    "    return error_columns\n",
    "\n",
    "# Find the optimal distance\n",
    "for eps in np.arange(.1,5,.1):\n",
    "    db = DBSCAN(min_samples=1, eps=eps)\n",
    "    labels = db.fit_predict(values)\n",
    "\n",
    "    # Assume that there should only be at most 2 points in a cluster.\n",
    "    # This assumption may be wrong.\n",
    "    # If there is a bin with 3 or more, stop looping and and revert to previous value\n",
    "    # We also know that there should only be two feaures with errors (from question b)\n",
    "    # So stop if we get more.\n",
    "    if max(np.bincount(labels)) > 2 or len(getErrorFeatures(labels)) > 2:\n",
    "        break\n",
    "\n",
    "# Readjust eps\n",
    "eps -= .1\n",
    "print(\"Optimal eps:\", eps)\n",
    "\n",
    "db = DBSCAN(min_samples=1, eps=eps)\n",
    "labels = db.fit_predict(values)\n",
    "\n",
    "print(\"Features with errors:\", getErrorFeatures(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, since the points won't be exactly in the same place, we're not sure how far apart we should expect them to be.  I assumed that there would only be one duplicate of any particular row (which may be a wrong assumption) and searched for the correct distance (eps) using that assumption. After doing that, I found the features that were altered by diffing the features in each cluster to find non-zero differences.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('cpw_stops_2012.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\docmario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\Users\\docmario\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "values = scale(data.applymap(lambda x: hash(x)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km = KMeans()\n",
    "labels = km.fit_predict(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
