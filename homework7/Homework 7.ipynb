{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Display plots in the notebook\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make plots prettyful\n",
    "pl.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('original_with_duplicates_noid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\docmario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "values = scale(pd.get_dummies(data, columns=['year', 'day', 'month', 'suspect.race', 'suspect.build', 'suspect.sex', 'location.housing']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements via clustering: 997\n"
     ]
    }
   ],
   "source": [
    "db = DBSCAN(min_samples=1, eps=1)\n",
    "labels = db.fit_predict(values)\n",
    "print(\"Number of unique elements via clustering:\", len(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements via row-wise detection: 997\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique elements via row-wise detection:\", len(data[~data.duplicated()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first hashed the data to convert all the data to numeric types (instead of strings0. I used DBSCAN to cluster the data using all the columns in the dataset.  I used DBSCAN because it does not require the number of clusters to be specified.  \n",
    "\n",
    "I used pandas's built in duplicate detection to validate this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('original_with_errors_noid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=1000)\n",
    "labels = km.fit_predict(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\docmario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\Users\\docmario\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal eps: 1.3\n"
     ]
    }
   ],
   "source": [
    "values = scale(data.applymap(lambda x: hash(x)).values)\n",
    "\n",
    "# Find the optimal distance\n",
    "for eps in np.arange(.1,5,.1):\n",
    "    db = DBSCAN(min_samples=1, eps=eps)\n",
    "    labels = db.fit_predict(values)\n",
    "\n",
    "    # Assume that there should only be at most 2 points in a cluster.\n",
    "    # This assumption may be wrong.\n",
    "    # If there is a bin with 3 or more, stop looping and and revert to previous value\n",
    "    if max(np.bincount(labels)) > 2:\n",
    "        break\n",
    "\n",
    "# Readjust eps\n",
    "eps -= .1\n",
    "print(\"Optimal eps:\", eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rerun DBSCAN with optimal EPS\n",
    "db = DBSCAN(min_samples=1, eps=eps)\n",
    "labels = db.fit_predict(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements via clustering: 997\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique elements via clustering:\", len(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with errors: {'suspect.weight', 'suspect.age'}\n"
     ]
    }
   ],
   "source": [
    "# Figure out which features had errors introduced by diffing the rows in each cluster and picking out the non-zero features\n",
    "error_columns = set()\n",
    "for i in np.nonzero(np.bincount(labels) > 1)[0]:\n",
    "    columns = data.columns[np.nonzero(np.diff(values[labels == i], axis=0)[0])]\n",
    "    for c in columns:\n",
    "        error_columns.add(c)\n",
    "print(\"Features with errors:\", error_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>found.weapon</th>\n",
       "      <th>found.gun</th>\n",
       "      <th>arrested</th>\n",
       "      <th>suspect.race</th>\n",
       "      <th>suspect.age</th>\n",
       "      <th>suspect.build</th>\n",
       "      <th>suspect.sex</th>\n",
       "      <th>suspect.height</th>\n",
       "      <th>suspect.weight</th>\n",
       "      <th>...</th>\n",
       "      <th>additional.associating</th>\n",
       "      <th>additional.direction</th>\n",
       "      <th>additional.highcrime</th>\n",
       "      <th>additional.time</th>\n",
       "      <th>additional.sights</th>\n",
       "      <th>additional.other</th>\n",
       "      <th>radio.run</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>time.period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>black</td>\n",
       "      <td>24</td>\n",
       "      <td>medium</td>\n",
       "      <td>male</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>155</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Monday</td>\n",
       "      <td>August</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>2012</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>black</td>\n",
       "      <td>21</td>\n",
       "      <td>medium</td>\n",
       "      <td>male</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Monday</td>\n",
       "      <td>August</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year found.weapon found.gun arrested suspect.race  suspect.age  \\\n",
       "1    2012        False     False    False        black           24   \n",
       "939  2012        False     False    False        black           21   \n",
       "\n",
       "    suspect.build suspect.sex  suspect.height  suspect.weight     ...      \\\n",
       "1          medium        male        5.666667             155     ...       \n",
       "939        medium        male        5.666667             160     ...       \n",
       "\n",
       "    additional.associating additional.direction additional.highcrime  \\\n",
       "1                    False                False                 True   \n",
       "939                  False                False                 True   \n",
       "\n",
       "    additional.time additional.sights additional.other radio.run     day  \\\n",
       "1             False             False            False     False  Monday   \n",
       "939           False             False            False     False  Monday   \n",
       "\n",
       "      month time.period  \n",
       "1    August           6  \n",
       "939  August           6  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[labels == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, since the points won't be exactly in the same place, we're not sure how far apart we should expect them to be.  I assumed that there would only be one duplicate of any particular row (which may be a wrong assumption) and searched for the correct distance (eps) using that assumption. After doing that, I found the features that were altered by diffing the features in each cluster to find non-zero differences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ,  1.1,\n",
       "        1.2,  1.3,  1.4,  1.5,  1.6,  1.7,  1.8,  1.9])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(.1,2,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('cpw_stops_2012.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\docmario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\Users\\docmario\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "values = scale(data.applymap(lambda x: hash(x)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km = KMeans()\n",
    "labels = km.fit_predict(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
