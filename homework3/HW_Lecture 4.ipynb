{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (20% credit)\n",
    "\n",
    "Assume you have a data set as below. It contains records of cars with three features: the type of the car (sports(1) or SUV(2)), the color of the car (red(1) or yellow(2)), and the origin of the car (domestic(1) or imported(2)). And the labels for the data are: stolen(1) and not(0). \n",
    "\n",
    "#### Questions:\n",
    "\n",
    "a) Calculate the following sample probabilities:\n",
    "P(Red|Stolen), P(SUV|Stolen), P(Domestic|Stolen), P(Red|Not Stolen) , P(SUV|Not Stolen), and P(Domestic|Not Stolen)\n",
    "\n",
    "b) Suggest a classification for a red, domestic SUV - whether it will be stolen or not - using Naive Bayes classifier. \n",
    "\n",
    "Please perform all the necessary computations \"by hands\" rather than using python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import math\n",
    "y=[1,0,1,0,1,0,1,0,0,1]\n",
    "X=[[1,1,1,2,2,2,2,2,1,1],[1,1,1,1,1,2,2,2,2,1],[1,1,1,1,2,2,2,1,2,2]]\n",
    "data=[y]+X\n",
    "data=pd.DataFrame(data).T\n",
    "data.columns=['Stolen?','Color','Type','Origin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(a)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Stolen) =  0.5\n",
      "P(Red|Stolen) =  0.6\n",
      "P(SUV|Stolen) =  0.2\n",
      "P(Domestic|Stolen) =  0.4\n",
      "P(Red|Not Stolen) =  0.4\n",
      "P(SUV|Not Stolen) =  0.6\n",
      "P(Domestic|Not Stolen) =  0.6\n"
     ]
    }
   ],
   "source": [
    "print \"P(Stolen) = \", 1.*len(data[(data['Stolen?']==1)])/len(data)\n",
    "print \"P(Red|Stolen) = \", 1.*len(data[(data['Stolen?']==1)&(data['Color']==1)])/len(data[data['Stolen?']==1])\n",
    "print \"P(SUV|Stolen) = \", 1.*len(data[(data['Stolen?']==1)&(data['Type']==2)])/len(data[data['Stolen?']==1])\n",
    "print \"P(Domestic|Stolen) = \", 1.*len(data[(data['Stolen?']==1)&(data['Origin']==1)])/len(data[data['Stolen?']==1])\n",
    "print \"P(Red|Not Stolen) = \", 1.*len(data[(data['Stolen?']==0)&(data['Color']==1)])/len(data[data['Stolen?']==0])\n",
    "print \"P(SUV|Not Stolen) = \", 1.*len(data[(data['Stolen?']==0)&(data['Type']==2)])/len(data[data['Stolen?']==0])\n",
    "print \"P(Domestic|Not Stolen) = \", 1.*len(data[(data['Stolen?']==0)&(data['Origin']==1)])/len(data[data['Stolen?']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Stolen|{Red, Domestic, SUV}) = P(Red|Stolen) * P(Domestic|Stolen) * P(SUV|Stolen) * P(Stolen) =  0.024\n",
      "P(Not Stolen|{Red, Domestic, SUV}) = P(Red|Not Stolen) * P(Domestic|Not Stolen) * P(SUV|Not Stolen) * P(Not Stolen) =  0.072\n"
     ]
    }
   ],
   "source": [
    "print \"P(Stolen|{Red, Domestic, SUV}) = P(Red|Stolen) * P(Domestic|Stolen) * P(SUV|Stolen) * P(Stolen) = \", .6*.4*.2*.5\n",
    "print \"P(Not Stolen|{Red, Domestic, SUV}) = P(Red|Not Stolen) * P(Domestic|Not Stolen) * P(SUV|Not Stolen) * P(Not Stolen) = \", .4*.6*.6*.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(Not Stolen|{Red, Domestic, SUV}) > P(Stolen|{Red, Domestic, SUV}) -> Not Stolen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (25% credit)\n",
    "Consider a following Guassian Naive Bayes problem.\n",
    "We use eight factors to predict if people have diabetes or not. The variabls are:\n",
    "\n",
    "y: The label (0 - no diabetes, 1 - diabetes)\n",
    "\n",
    "t_pre: Number of times pregnant\n",
    "\n",
    "glu: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "\n",
    "blood_p: Diastolic blood pressure (mm Hg)\n",
    "\n",
    "triceps: Triceps skin fold thickness (mm)\n",
    "\n",
    "serum: 2-Hour serum insulin (mu U/ml)\n",
    "\n",
    "b_m: Body mass index (weight in kg/(height in m)^2)\n",
    "\n",
    "pedigree_f: Diabetes pedigree function\n",
    "\n",
    "age: Age (years)\n",
    "#### ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#### Questions:\n",
    "\n",
    "a)Train the classifier: use the training data to estimate prior probabilities $P(y=b)$ as well as the parameters (mean and standard deviation) of the sample distributions $P(x_i|y=b)$.\n",
    "\n",
    "b)Perform the classification for the test sample. \n",
    "\n",
    "c)Compare your result to y_test and report the classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(a)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train=pd.read_csv(\"dia_train.csv\", usecols=range(1,10)) \n",
    "\n",
    "data_test=pd.read_csv(\"dia_test.csv\", usecols=range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNaiveBayes(trainData):\n",
    "  #training Gausian Naive Bayes Classifier\n",
    "  tY=trainData.loc[:,trainData.columns[0]]\n",
    "  ind1=tY==0\n",
    "  ind2=tY==1\n",
    "  dp=pd.DataFrame(columns=trainData.columns, index=['mu1','sigma1','mu2','sigma2'])\n",
    "  #estimate priors\n",
    "  dp[trainData.columns[0]]['mu1']=1.0*sum(ind1)/len(trainData.index)\n",
    "  dp[trainData.columns[0]]['mu2']=1.0*sum(ind2)/len(trainData.index)\n",
    "  #estimate sample distribution paramters for p(xi|y=b)\n",
    "  for i in trainData.columns[1:]:\n",
    "    dp.loc['mu1',i]=(trainData[i][ind1]).mean()\n",
    "    dp.loc['sigma1',i]=(trainData[i][ind1]).std()\n",
    "    dp.loc['mu2',i]=(trainData[i][ind2]).mean()\n",
    "    dp.loc['sigma2',i]=(trainData[i][ind2]).std()\n",
    "  return dp\n",
    "\n",
    "def classifyNaiveBayes(classData,dp):\n",
    "  #classifying using trained Gausian Naive Bayes Classifier\n",
    "  Y=classData.loc[:,classData.columns[0]]*0\n",
    "  for j in classData.index:\n",
    "    #start from the priors\n",
    "    P1=dp[classData.columns[0]]['mu1'];\n",
    "    P2=dp[classData.columns[0]]['mu2'];\n",
    "    #multiply by conditional probability densities p(xi|y=b)\n",
    "    for i in classData.columns[1:]:\n",
    "        if dp[i]['sigma1']==0: #if sigma can not be defined (sample does not have variance)\n",
    "            P1=P1*stats.norm.pdf(classData[i][j], loc=dp[i]['mu1'],scale=1) #pick up arbitrary sigma if undefined\n",
    "        else:\n",
    "            P1=P1*stats.norm.pdf(classData[i][j], loc=dp[i]['mu1'],scale=dp[i]['sigma1'])\n",
    "        \n",
    "        if dp[i]['sigma2']==0: #if sigma can not be defined (sample does not have variance)\n",
    "            P2=P2*stats.norm.pdf(classData[i][j], loc=dp[i]['mu2'],scale=1) #pick up arbitrary sigma if undefined\n",
    "        else:\n",
    "            P2=P2*stats.norm.pdf(classData[i][j], loc=dp[i]['mu2'],scale=dp[i]['sigma2']) \n",
    "    Y[j]=int(P2>P1)\n",
    " \n",
    "\n",
    "  return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp=trainNaiveBayes(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>t_pre</th>\n",
       "      <th>glu</th>\n",
       "      <th>blood_p</th>\n",
       "      <th>triceps</th>\n",
       "      <th>serum</th>\n",
       "      <th>b_m</th>\n",
       "      <th>pedigree_f</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mu1</th>\n",
       "      <td>0.6991525</td>\n",
       "      <td>2.690909</td>\n",
       "      <td>111.4667</td>\n",
       "      <td>69.20606</td>\n",
       "      <td>27.2</td>\n",
       "      <td>127.0061</td>\n",
       "      <td>31.70909</td>\n",
       "      <td>0.4686848</td>\n",
       "      <td>28.39394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.610061</td>\n",
       "      <td>24.69189</td>\n",
       "      <td>11.71329</td>\n",
       "      <td>10.43692</td>\n",
       "      <td>91.48614</td>\n",
       "      <td>6.337613</td>\n",
       "      <td>0.2917503</td>\n",
       "      <td>8.537362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu2</th>\n",
       "      <td>0.3008475</td>\n",
       "      <td>4.070423</td>\n",
       "      <td>144.1408</td>\n",
       "      <td>74.56338</td>\n",
       "      <td>33.47887</td>\n",
       "      <td>209.2113</td>\n",
       "      <td>35.22394</td>\n",
       "      <td>0.6390423</td>\n",
       "      <td>35.78873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.51862</td>\n",
       "      <td>30.62646</td>\n",
       "      <td>13.79931</td>\n",
       "      <td>9.762697</td>\n",
       "      <td>126.921</td>\n",
       "      <td>6.258491</td>\n",
       "      <td>0.439042</td>\n",
       "      <td>10.26355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                y     t_pre       glu   blood_p   triceps     serum       b_m  \\\n",
       "mu1     0.6991525  2.690909  111.4667  69.20606      27.2  127.0061  31.70909   \n",
       "sigma1        NaN  2.610061  24.69189  11.71329  10.43692  91.48614  6.337613   \n",
       "mu2     0.3008475  4.070423  144.1408  74.56338  33.47887  209.2113  35.22394   \n",
       "sigma2        NaN   3.51862  30.62646  13.79931  9.762697   126.921  6.258491   \n",
       "\n",
       "       pedigree_f       age  \n",
       "mu1     0.4686848  28.39394  \n",
       "sigma1  0.2917503  8.537362  \n",
       "mu2     0.6390423  35.78873  \n",
       "sigma2   0.439042  10.26355  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C=classifyNaiveBayes(data_test,dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(c)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy for test set = 0.791139240506\n"
     ]
    }
   ],
   "source": [
    "print \"Classification accuracy for test set =\", 1.0*sum(C==data_test.y)/len(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (Credit 25%)\n",
    "We have an artificial data set split, while the training set contains both - labeled (Label_train) and unlabeled (Unlabel) data. Column 'y' is the label, and columns '0','1','2' are categorical variables.\n",
    "\n",
    "#### Questions:\n",
    "\n",
    "a) Use the labeled part data_train to predict the labels of X_Label_test, and report the classification accuracy.\n",
    "\n",
    "b) Improve the classification by using the unlabeled data data_Unlabel and the EM algorithm to predict labels of X_Label_test, and report the new accuracy by EM semi-supervised algorithm (use the same convergence criteria as in the lecture notebook). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train=pd.read_csv(\"EM_train.csv\", usecols=range(1,5))\n",
    "data_test=pd.read_csv(\"EM_test.csv\", usecols=range(1,5))\n",
    "data_Unlabel=pd.read_csv(\"EM_Unlabel.csv\", usecols=range(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNaiveBayesDiscrete(trainData):\n",
    "  #training discrete Naive Bayes Classifier\n",
    "  tY=trainData.loc[:,trainData.columns[0]]\n",
    "  m=max([trainData[j][i] for j in trainData.columns[1:] for i in trainData.index]) #maximal number of classes in each feature of a training set\n",
    "  #create output data structure for the probabilities - same column labels, rows correspond to values of x and there are two arrays like that for different b\n",
    "  dp=[pd.DataFrame(columns=trainData.columns, index=range(1,m+1)), pd.DataFrame(columns=trainData.columns, index=range(1,m+1))]\n",
    "  #split the training data between two labels\n",
    "  ind1=tY==0\n",
    "  ind2=tY==1\n",
    "  #estimate P(y=b)  \n",
    "  dp[0][trainData.columns[0]][1]=1.0*ind1.sum()/len(trainData.index)\n",
    "  dp[1][trainData.columns[0]][1]=1.0*ind2.sum()/len(trainData.index)\n",
    "  #estimate conditional probabilities P(x|y=b)\n",
    "  for j in trainData.columns[1:]:\n",
    "    for i in range(1,m+1):\n",
    "        dp[0].loc[i,j]=1.0*(trainData[j][ind1]==i).sum()/ind1.sum();\n",
    "        dp[1].loc[i,j]=1.0*(trainData[j][ind2]==i).sum()/ind2.sum();\n",
    "  return dp\n",
    "\n",
    "def classifyNaiveBayesDiscrete(classData,dp):\n",
    "  #classifying using trained discrete Naive Bayes Classifier\n",
    "  Y=classData[classData.columns[0]]*0 #initialize the empty array \n",
    "  for i in classData.index: #for al records to classify\n",
    "    #start with the priors\n",
    "    P1=dp[0][classData.columns[0]][1]; \n",
    "    P2=dp[1][classData.columns[0]][1];\n",
    "    #and multiply them by the corresponding conditional probabilities P(x_i|y=b)\n",
    "    for j in classData.columns[1:]:\n",
    "      P1=P1*dp[0][j][classData[j][i]]\n",
    "      P2=P2*dp[1][j][classData[j][i]]\n",
    "    Y[i]=int(P2>P1) #finally for each record decide which P(y|x) is higher and choose the label\n",
    "  return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(a)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy for test set = 0.638888888889\n"
     ]
    }
   ],
   "source": [
    "dp=trainNaiveBayesDiscrete(data_train)\n",
    "C=classifyNaiveBayesDiscrete(data_test,dp)\n",
    "print \"Classification accuracy for test set =\", 1.0*sum(C==data_test.y)/len(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implementation of Expectation-Maximization algorithm for partially labeled data\n",
    "def EM(X_Label,y_Label,X_Unlabel,dp):\n",
    "  t = 0  \n",
    "  haslabels=len(y_Label)>0\n",
    "\n",
    "  while True:\n",
    "    t = t + 1\n",
    "\n",
    "    classData=X_Unlabel\n",
    "    # Now we want to calculate P(y=1|x) and P(y=2|x) for all observations xj. (these are bunch of scalars)\n",
    "    # we need this to calculate new dp. Basically speaking, for every new iteration we need a new dp.\n",
    "\n",
    "    #for y=1 and y=2\n",
    "\n",
    "    p_x_1=[] #unnormalized P(y=1|x)\n",
    "    p_x_2=[] #unnormalized P(y=2|x)\n",
    "    cols=dp[0].columns\n",
    "\n",
    "    for i in classData.index:\n",
    "        P1=dp[0][cols[0]][1];\n",
    "        P2=dp[1][cols[0]][1];\n",
    "        for j in classData.columns:\n",
    "            P1=P1*dp[0][j][classData[j][i]]\n",
    "            P2=P2*dp[1][j][classData[j][i]]\n",
    "        p_x_1.append(P1)\n",
    "        p_x_2.append(P2)\n",
    "\n",
    "    #Rescale p_x_1 and p_x_2:\n",
    "    summ=np.asarray(p_x_1)+np.asarray(p_x_2)\n",
    "    p_x_1_s=np.asarray(p_x_1)/summ\n",
    "    p_x_2_s=np.asarray(p_x_2)/summ\n",
    "    inds_1 = np.where(np.isnan(p_x_1_s))\n",
    "    inds_2 = np.where(np.isnan(p_x_2_s))\n",
    "    p_x_1_s[inds_1]=0.5\n",
    "    p_x_2_s[inds_2]=0.5\n",
    "    #Now let's calculate P(y=1) and P(y=2)\n",
    "    p_1=p_x_1_s.sum()/len(p_x_1_s)\n",
    "    p_2=p_x_2_s.sum()/len(p_x_2_s)\n",
    "\n",
    "\n",
    "    #Now let's calculate the probability distribution of P(xi|y=1) and P(xi|y=2)\n",
    "    \n",
    "    m=max([classData[j][i] for j in classData.columns for i in classData.index]) #maximal number of classes in each feature of a training set\n",
    "\n",
    "    #create output data structure for the probabilities - new iteration\n",
    "    \n",
    "    dp1=[pd.DataFrame(columns=cols, index=range(1,m+1)), pd.DataFrame(columns=cols, index=range(1,m+1))]\n",
    "\n",
    "    #P(y=b)  \n",
    "    dp1[0][cols[0]][1]=p_1\n",
    "    dp1[1][cols[0]][1]=p_2\n",
    "\n",
    "\n",
    "    #estimate conditional probabilities P(x|y=b) -do we add labeled data to fit?\n",
    "\n",
    "    temp=np.concatenate((np.asmatrix(X_Unlabel),np.asarray(pd.DataFrame(p_x_1_s)),np.asarray(pd.DataFrame(p_x_2_s))), axis=1)\n",
    "    temp=pd.DataFrame(temp)\n",
    "    if haslabels:\n",
    "        temp_l=np.concatenate((np.asmatrix(X_Label),np.asmatrix(1*(y_Label==0)).transpose(),np.asmatrix(1*(y_Label==1)).transpose()),axis=1)\n",
    "        temp_l=pd.DataFrame(temp_l)\n",
    "        pd.concat([temp,temp_l])\n",
    "   \n",
    "\n",
    "    for j in range(1,len(dp[0].T)):\n",
    "        for i in range(len(dp[0])):\n",
    "\n",
    "            dp1[0].iloc[i,j]=temp[temp.iloc[:,j-1]==i+1].iloc[:,-2].sum()/temp.iloc[:,-2].sum()\n",
    "            dp1[1].iloc[i,j]=temp[temp.iloc[:,j-1]==i+1].iloc[:,-1].sum()/temp.iloc[:,-1].sum()\n",
    "\n",
    "        ############################################################################################\n",
    "    # Now we use dp to decide whether to continue our iterations\n",
    "    #print dp[0]\n",
    "    #print np.sum((dp1[0] - dp[0])**2)\n",
    "    #print dp[1]\n",
    "    #print np.sum((dp1[1] - dp[1])**2)\n",
    "    if (sum(np.sum((dp1[0]-dp[0])**2))+sum(np.sum((dp1[1]-dp[1])**2)))<0.001: #if dp does not change much\n",
    "        break\n",
    "    else: \n",
    "        dp=dp1  #save new dp and perform next iteration\n",
    "\n",
    "        \n",
    "    ###############################################################################################\n",
    "        #Calculate the log-likelihood\n",
    "        \n",
    "        L=0\n",
    "        \n",
    "        for i in classData.index:\n",
    "            P1=dp[0][cols[0]][1];\n",
    "            P2=dp[1][cols[0]][1];\n",
    "            for j in classData.columns:\n",
    "                P1=P1*dp[0][j][classData[j][i]]\n",
    "                P2=P2*dp[1][j][classData[j][i]]\n",
    "            temp=math.log(P1+P2)\n",
    "            L=L+temp\n",
    "        if haslabels:    \n",
    "          for i in X_Label.index:\n",
    "            yi=y_Label[i]\n",
    "            P=dp[yi][cols[0]][1];\n",
    "            for j in X_Label.columns:\n",
    "                P=P*dp[yi][j][X_Label[j][i]]\n",
    "            L=L+math.log(P)\n",
    "        \n",
    "        #print \"Iteration {0}: log maximum liklihood = {1}\".format(t,L)    \n",
    "        \n",
    "        \n",
    "  return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy for test set after EM = 0.944444444444\n"
     ]
    }
   ],
   "source": [
    "dpEM = EM(data_train.iloc[:,1:], data_train.iloc[:,0], data_Unlabel, dp)\n",
    "C=classifyNaiveBayesDiscrete(data_test,dpEM) #classify test data with a new theta given by EM\n",
    "print \"Classification accuracy for test set after EM =\", 1.0*sum(C==data_test.y)/len(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (Credit 30%)\n",
    "For the similar artifitial data uploaded below:\n",
    "\n",
    "#### Question: \n",
    "\n",
    "a) Apply the EM algorithm (no observed labels, random initial choice of $\\theta$) for clustering the data records into two clusters. Report your result (a vector of cluster numbers for each data record). \n",
    "\n",
    "b) Repeat the clustering 10 times with different random choices of $\\theta$ and analyze the stability of the clustering (matching labels accross different clusterings (use the choice of 0 and 1 labels best matching the previous clustering), estimate average label and its standard error for each record)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(a)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "5      0\n",
      "6      1\n",
      "7      0\n",
      "8      0\n",
      "9      1\n",
      "10     1\n",
      "11     1\n",
      "12     1\n",
      "13     0\n",
      "14     0\n",
      "15     0\n",
      "16     1\n",
      "17     0\n",
      "18     1\n",
      "19     1\n",
      "20     1\n",
      "21     0\n",
      "22     1\n",
      "23     1\n",
      "24     0\n",
      "25     1\n",
      "26     0\n",
      "27     0\n",
      "28     0\n",
      "29     1\n",
      "      ..\n",
      "75     0\n",
      "76     0\n",
      "77     1\n",
      "78     0\n",
      "79     1\n",
      "80     1\n",
      "81     1\n",
      "82     0\n",
      "83     1\n",
      "84     1\n",
      "85     0\n",
      "86     0\n",
      "87     0\n",
      "88     0\n",
      "89     1\n",
      "90     1\n",
      "91     0\n",
      "92     1\n",
      "93     1\n",
      "94     0\n",
      "95     1\n",
      "96     0\n",
      "97     1\n",
      "98     1\n",
      "99     0\n",
      "100    1\n",
      "101    1\n",
      "102    1\n",
      "103    0\n",
      "104    0\n",
      "Name: y, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "data=pd.read_csv(\"EM_Cluster.csv\")\n",
    "X=data.iloc[:,1:]\n",
    "\n",
    "# Random Ys\n",
    "Y = np.random.randint(0,2,len(X))\n",
    "X.insert(0, 'y', Y)\n",
    "\n",
    "dp=trainNaiveBayesDiscrete(X)\n",
    "dpEM = EM([], [], X.iloc[:,1:], dp)\n",
    "C=classifyNaiveBayesDiscrete(X,dpEM)\n",
    "\n",
    "print C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    data=pd.read_csv(\"EM_Cluster.csv\")\n",
    "    X=data.iloc[:,1:]\n",
    "\n",
    "    # Random Ys\n",
    "    Y = np.random.randint(0,2,len(X))\n",
    "    X.insert(0, 'y', Y)\n",
    "\n",
    "    dp=trainNaiveBayesDiscrete(X)\n",
    "    dpEM = EM([], [], X.iloc[:,1:], dp)\n",
    "    C=classifyNaiveBayesDiscrete(X,dpEM)\n",
    "    results[i] = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Correct for opposite labelings by assuming a stability of > 75\n",
    "while np.any(np.sum(np.abs(np.diff(results)), axis=0) > 75):\n",
    "    # Get the first column which is opposite of the previous\n",
    "    i = np.argmax(np.sum(np.abs(np.diff(results)), axis=0) > 75)\n",
    "    \n",
    "    # Invert it\n",
    "    results[i] = (~results[i].astype(bool)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:\n",
      "16    0.8\n",
      "22    0.1\n",
      "32    0.1\n",
      "47    0.7\n",
      "56    0.7\n",
      "75    0.7\n",
      "89    0.1\n",
      "93    0.1\n",
      "dtype: float64\n",
      "\n",
      "standard errors:\n",
      "16    0.133333\n",
      "22    0.100000\n",
      "32    0.100000\n",
      "47    0.152753\n",
      "56    0.152753\n",
      "75    0.152753\n",
      "89    0.100000\n",
      "93    0.100000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the means and errors of the elements which are not stable\n",
    "means = results.mean(axis=1)\n",
    "print \"means:\"\n",
    "print means[(means>0)&(means<1)]\n",
    "\n",
    "se = results.std(axis=1)/math.sqrt(10)\n",
    "print \"\\nstandard errors:\"\n",
    "print se[(means>0)&(means<1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
